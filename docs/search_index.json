[["index.html", "Stocastic Chapter 1 Premilaries 1.1 Brownian Motion 1.2 Definition of Brownian Motion 1.3 Simple Properties of Brownian Motion 1.4 Wiener Integral", " Stocastic Ashan Jayamal 2024-07-30 Chapter 1 Premilaries Definition 1.1 Consider a set \\(X\\). An \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) of subsets of \\(X\\) is a collection \\(\\mathcal{F}\\) of subsets of \\(X\\) satisfying the following conditions: \\(\\emptyset \\in \\mathcal{F}\\) If \\(B \\in \\mathcal{F}\\), then its complement \\(B^c\\) is also in \\(F\\) If \\(B_1, B_2, \\ldots\\) is a countable collection of sets in \\(\\mathcal{F}\\), then their union \\(\\bigcup_{n=1}^\\infty B_n\\) is also in \\(\\mathcal{F}\\). 1.1 Brownian Motion Let \\((\\Omega, F, P)\\) be a probability space. A stochastic process is a measurable function \\(X(t, \\omega)\\) defined on the product space \\([0,\\infty) \\times \\Omega\\). In particular: For each \\(t\\), \\(X(t, \\cdot)\\) is a random variable. For each \\(\\omega\\), \\(X(\\cdot, \\omega)\\) is a measurable function (called a sample path). For convenience, the random variable \\(X(t, \\cdot)\\) will be written as \\(X(t)\\) or \\(X_t\\). Thus, a stochastic process \\(X(t, \\omega)\\) can also be expressed as \\(X(t)(\\omega)\\) or simply as \\(X(t)\\) or \\(X_t\\). 1.2 Definition of Brownian Motion (#def:Brownian_Motaion) A stochastic process \\(B(t, \\omega)\\) is called a Brownian motion if it satisfies the following conditions: \\(P(\\{\\omega : B(0, \\omega) = 0\\}) = 1\\). For any \\(0 \\leq s &lt; t\\), the random variable \\(B(t) - B(s)\\) is normally distributed with mean 0 and variance \\(t - s\\), i.e., for any \\(a &lt; b\\), \\[ P(a \\leq B(t) - B(s) \\leq b) = \\frac{1}{\\sqrt{2\\pi(t - s)}} \\int_a^b e^{-x^2/2(t - s)} \\, dx. \\] \\(B(t, \\omega)\\) has independent increments, i.e., for any \\(0 \\leq t_1 &lt; t_2 &lt; \\ldots &lt; t_n\\), the random variables \\[B(t_1), B(t_2) - B(t_1), \\ldots, B(t_n) - B(t_{n-1})\\] are independent. Almost all sample paths of \\(B(t, \\omega)\\) are continuous functions, i.e., \\[P(\\{\\omega : B(\\cdot, \\omega) \\text{ is continuous}\\}) = 1\\]. 1.3 Simple Properties of Brownian Motion Let\\(B(t)\\) be a fixed Brownian motion. We give below some simple properties that follow directly from the definition of Brownian motion. Proposition 1.1 For any \\(t &gt; 0\\), \\(B(t)\\) is normally distributed with mean 0 and variance \\(t\\). For any \\(s, t \\geq 0\\), we have \\(\\mathbb{E}[B(s)B(t)] = \\min\\{s, t\\}\\). Remark. Regarding Definition @ref(def:Brownian_Motaion), it can be proved that condition (2) and E[B(s)B(t)] = min{s, t} imply condition (3). Proof. By condition (1), we have \\(B(t) = B(t)−B(0)\\) and so the first assertion follows from condition (2). With out loss of generlity, assume that \\(s&lt;t\\). \\[\\mathbb{E}[B(s)B(t)] = \\mathbb{E}[B(s)(B(t) - B(s)) + B(s)^2]= 0 + s = s\\] which is equal to \\(\\min\\{s, t\\}\\). Proposition 1.2 (Translation Invariance) For a fixed \\(t_0 \\geq 0\\), the stochastic process \\(B(t) = B(t + t_0) - B(t_0)\\) is also a Brownian motion. Proposition 1.3 (Scaling invariance) For any real number \\(\\lambda &gt; 0\\), the stochastic process \\(B(t) = \\frac{B(\\lambda t)}{\\sqrt{\\lambda}}\\) is also a Brownian motion. 1.4 Wiener Integral "],["introduction.html", "Chapter 2 Introduction 2.1 Events and Probability 2.2 Random Variables", " Chapter 2 Introduction 2.1 Events and Probability Definition 2.1 Let \\(\\Omega\\) be a non-empty set. A \\(\\sigma\\)-field \\(\\mathcal{F}\\) on \\(\\Omega\\) is a family of subsets of \\(\\Omega\\) such that: The empty set \\(\\emptyset\\) belongs to \\(\\mathcal{F}\\); If \\(A\\) belongs to \\(\\mathcal{F}\\), then so does the complement \\(\\Omega \\setminus A\\); If \\(A_1, A_2, \\ldots\\) is a sequence of sets in \\(\\mathcal{F}\\), then their union \\(A_1 \\cup A_2 \\cup \\cdots\\) also belongs to \\(\\mathcal{F}\\). Example 2.1 a Definition 2.2 Let \\(\\mathcal{F}\\) be a \\(\\sigma\\)-field on \\(\\Omega\\). A probability measure \\(P\\) is a function \\(P : \\mathcal{F} \\to [0, 1]\\) such that \\(P(\\Omega) = 1\\); if \\(A_1, A_2, \\ldots\\) are pairwise disjoint sets (that is, \\(A_i \\cap A_j = \\emptyset\\) for \\(i \\neq j\\)) belonging to \\(\\mathcal{F}\\), then \\[ P\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} P(A_i); \\] The triple \\((\\Omega, \\mathcal{F}, P)\\) is called a probability space. The sets belonging to \\(\\mathcal{F}\\) are called events. An event \\(A\\) is said to occur almost surely (a.s.) whenever \\(P(A) = 1\\). Example 2.2 Let consider, \\(\\Omega=[0, 1]\\) with the \\(\\sigma\\)-field =\\(\\mathcal{F} = \\mathcal{B}([0, 1])\\) of Borel sets \\(B \\subseteq [0, 1]\\), and Lebesgue measure \\(P = \\text{Leb}\\) on \\([0, 1]\\). Then \\((\\Omega, \\mathcal{F}, P)\\) is a probability space. Recall that \\(\\text{Leb}\\) is the unique measure defined on Borel sets such that [a, b] = b - a] for any interval \\([a, b]\\). (In fact, \\(\\text{Leb}\\) can be extended to a larger \\(\\sigma\\)-field, but we shall need Borel sets only.) Exercise 2.1 Show that if \\(A_1, A_2, \\ldots\\) is an expanding sequence of events, that is \\[ A_1 \\subseteq A_2 \\subseteq A_3 \\subseteq \\cdots \\] then \\[ P\\left(\\bigcup_{n=1}^{\\infty} A_n\\right) = \\lim_{n \\to \\infty} P(A_n). \\] Similarly, if \\(A_1, A_2, \\ldots\\) is a contracting sequence of events, that is, \\[ A_1 \\supseteq A_2 \\supseteq A_3 \\supseteq \\cdots \\] then \\[ P\\left(\\bigcap_{n=1}^{\\infty} A_n\\right) = \\lim_{n \\to \\infty} P(A_n). \\] Hint: Write \\(A_1 \\cup A_2 \\cup \\cdots\\) as the union of a sequence of disjoint events: start with \\(A_1\\), then add a disjoint set to obtain \\(A_1 \\cup A_2\\), then add a disjoint set again to obtain \\(A_1 \\cup A_2 \\cup A_3\\), and so on. Now that you have a sequence of disjoint sets, you can use the definition of a probability measure. To deal with the product \\(A_1 \\cap A_2 \\cap \\cdots\\), write it as a union of some events with the aid of De Morgan’s law. Lemma 2.1 (Borei-Cantelli) Let \\(A_1, A_2, \\ldots\\) be a sequence of events such that \\(P(A_1) + P(A_2) + \\cdots &lt; \\infty\\) and let \\(B_n = A_n \\cup A_{n+1} \\cup \\cdots\\). Then \\(P(B_1 \\cap B_2 \\cap \\cdots) = 0\\). Exercise 2.2 Prove the Borel-Cantelli lemma above. Hint: \\(B_1, B_2, \\ldots\\) is a contracting sequence of events. 2.2 Random Variables Definition 2.3 If \\(\\mathcal{F}\\) is a \\(\\sigma\\)-field on \\(\\Omega\\), then a function \\(X : \\Omega \\to \\mathbb{R}\\) is said to be \\(\\mathcal{F}\\)-measurable if \\[\\{\\omega \\in \\Omega : X(\\omega) \\in B\\}=X^{-1}(\\omega)\\] for every Borel set \\(B \\in \\mathcal{B}(\\mathbb{R})\\). If \\((\\Omega, \\mathcal{F}, P)\\) is a probability space, then such a function \\(X\\) is called a random variable. Definition 2.4 The \\(\\sigma\\)-field \\(\\sigma(X)\\) generated by a random variable \\(X : \\Omega \\to \\mathbb{R}\\) consists of all sets of the form \\(\\{X \\in B\\}\\), where \\(B\\) is a Borel set in \\(\\mathbb{R}\\). Definition 2.5 The \\(\\sigma\\)-field \\(\\sigma(\\{X_i : i \\in I\\})\\) generated by a family \\(\\{X_i : i \\in I\\}\\) of random variables is defined to be the smallest \\(\\sigma\\)-field containing all events of the form \\(\\{X_i \\in B\\}\\), where \\(B\\) is a Borel set in \\(\\mathbb{R}\\) and \\(i \\in I\\). "],["random-walk-to-brownier-motion..html", "Chapter 3 Random Walk to Brownier Motion.", " Chapter 3 Random Walk to Brownier Motion. Slandered approach model stochastic dynamic in discrete time. Let \\(\\eta_i\\) be an random variable on a conman probability space. We often \\(\\Omega,\\mathcal{F},P\\) assume that i.i.d. This case \\(\\eta _i\\) is called white noise, otherwise coloured noise. Now we have definite dynamics. It will be given as discreate time dynamical systems recursively by some non linear function. We define, \\[\\begin{equation} X_{n+1}=X_n+\\phi_{n+1}(X_n,\\eta_{n+1}) \\quad n=0,1,2,...\\tag{3.1} \\end{equation}\\] where \\(\\phi_n:\\mathbb{R}^d\\times \\mathbb{R}^d\\to \\mathbb{R}^d\\) are measurable. Further, if \\(X_0\\) and \\(\\eta_0\\) are all independent then \\(X_n\\) is called Markov Chain. Now let \\(\\eta_i\\) be i.i.d and defineda random walk \\[\\begin{align} S_n&amp;:=\\sum_{i=1}^n \\eta_i\\\\ S_{(n+1)}&amp;:=S_n+\\eta_{(n+1)} \\end{align}\\] We can rewrite (3.1) as \\[X_{n+1}-X_n=\\phi_{n+1}(X_n,S_{n+1}-S_n)\\quad n=0,1,...\\] This equation is called Stochastic difference equations. AIM: Develop a continuous time analogous. Question What to use an contionus time replacement of the random walks? Definition 3.1 Let \\(I\\) be index set \\((I=\\mathbb{N} \\text{ or } I=\\mathbb{R}^+)\\). A collection of random varibels \\((X_t)_{i\\in I}\\) on \\((\\Omega,\\mathcal{F},P)\\) is called staocastic process. We need \\(I\\) to be a just totally ordered set for convention of time. If it is not an totally ordered set it is not a stochastic process but a random field. Now we need a notation of a filtration. Definition 3.2 Le \\(\\mathcal{F}_t\\) be non-decreasing sequnce of sub sigma algbers of \\(\\mathcal{F}\\) (i.e. \\(\\mathcal{F}_s\\subseteq \\mathcal{F}_t\\) for all \\(s\\geq t, s,t\\in \\in I\\)), then \\((\\mathcal{F}_t)_{t\\in I}\\) is called a filtration. Last we need the notation adaptness. Definition 3.3 A stocticstic process \\(X_t\\) is called adapted to filteration \\((\\mathcal{F}_t)_t\\) if \\(X_t\\in \\mathcal{F}_t\\). i.e: \\(X_t\\) is measurable Theorem 3.1 (Central Limit Theorem) Let \\(Y_{n_i}:\\Omega \\to \\mathbb{R}^d\\) (be collection of random varibles), \\(1\\leq i \\leq n &lt; \\infty\\) be identical distributed and square intergable random varaible on \\((\\Omega,\\mathcal{F},P)\\) such that \\(Y_{n_1},Y_{n_2},...,Y_{n_n}\\) are independent for all \\(n\\in \\mathbb{N}\\). Then \\[\\left(\\frac{1}{\\sqrt{n}}\\sum_{i=1}^n Y_{n_i}-\\mathbb{E}[Y_i] \\right) \\xrightarrow{\\mathcal{D}} N(0,C) \\text{ as } n \\to \\infty\\], where\\(N(0,C)\\) is multivarible noremal distribution with covarice matrix \\[Y_{k,l}=Cov[Y^{(k)}_{n_i} -Y^{(l)}_{n_i}]\\] and\\(\\xrightarrow{\\mathcal{D}}\\) means “distribution is convergent” to ``` Proof. Omitted We consider the random walk \\[S_n=\\sum_{i=1}^n\\eta_i\\] with \\(\\eta_i\\in L^2(\\Omega,\\mathcal{F},P)\\) and normalized.(i.e. \\(\\mathbb{E}[\\eta_i]=0,Var[\\eta_i]=1\\)) Plotting (Linear Interpolation) This gives an idea about the existance of a scaling limit. Now a question might be rising. Question: What is right rescaling? That is we try to define a rescaled random walk \\(S^m_t\\)(Here superscipt \\(m\\) is for mesh size), \\((t=0,\\frac{1}{m},\\frac{2}{m},cdots)\\) with step-size \\(\\frac{1}{m}\\) \\[S_{\\frac{k}{m}}^{(m)}=c_mS_k\\] Here \\(here c_m\\) is rescaling constant. It is difficulit to correct \\(c_m\\), because unless it decay so fast at the end you convert to zero or blow up whole thing and goes to infinity. For \\(t=\\frac{k}{m}\\) we have \\[Var[S_t^{(m)}]=c^2_m\\] "],["les.html", "Chapter 4 Les 4.1 Integrals 4.2 Random Walks", " Chapter 4 Les 4.1 Integrals First we review the definitions of the Riemann integral in calculus and the Riemann–Stieltjes integral in advanced calculus. 4.1.1 Riemann Integral Let \\(f\\) be an bounded function defined on a finite closed interval \\([a, b]\\). Then \\(f\\) is called Riemann integrable if the following limit exists. \\[\\begin{equation} x \\end{equation}\\] 4.2 Random Walks Consider a random walk starting at 0 with jumps \\(h\\) and \\(-h\\) equally likely at times \\(\\delta, 2\\delta,...\\), where \\(h,\\delta&gt;0\\) . More precisely, let \\(\\{X_n\\}_{n=1}^\\infty\\) be a sequence of independent and identically distributed random variables with \\[P(X_j = h) = P(X_j = −h) = \\frac{1}{2}\\] Let \\(Y_{\\delta,h}(0) =0\\) \\[Y_{\\delta,h}(n\\delta) = X_1 + X_2 + \\ldots + X_n\\] For \\(t &gt; 0\\) define \\(Y_{\\delta,h}(t)\\) by linearization: (i.e: For \\(n\\delta &lt; t &lt; (n + 1)\\delta\\), define \\[Y_{\\delta,h}(t) = \\frac{(n + 1)\\delta - t}{\\delta} Y_{\\delta,h}(n\\delta) + \\frac{t - n\\delta}{\\delta} Y_{\\delta,h}((n + 1)\\delta).\\] "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
