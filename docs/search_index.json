[["index.html", "Stocastic Chapter 1 Premilaries 1.1 Brownian Motion 1.2 Definition of Brownian Motion 1.3 Simple Properties of Brownian Motion 1.4 Wiener Integral", " Stocastic Ashan Jayamal 2024-07-26 Chapter 1 Premilaries Definition 1.1 Consider a set \\(X\\). An \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) of subsets of \\(X\\) is a collection \\(\\mathcal{F}\\) of subsets of \\(X\\) satisfying the following conditions: \\(\\emptyset \\in \\mathcal{F}\\) If \\(B \\in \\mathcal{F}\\), then its complement \\(B^c\\) is also in \\(F\\) If \\(B_1, B_2, \\ldots\\) is a countable collection of sets in \\(\\mathcal{F}\\), then their union \\(\\bigcup_{n=1}^\\infty B_n\\) is also in \\(\\mathcal{F}\\). 1.1 Brownian Motion Let \\((\\Omega, F, P)\\) be a probability space. A stochastic process is a measurable function \\(X(t, \\omega)\\) defined on the product space \\([0,\\infty) \\times \\Omega\\). In particular: For each \\(t\\), \\(X(t, \\cdot)\\) is a random variable. For each \\(\\omega\\), \\(X(\\cdot, \\omega)\\) is a measurable function (called a sample path). For convenience, the random variable \\(X(t, \\cdot)\\) will be written as \\(X(t)\\) or \\(X_t\\). Thus, a stochastic process \\(X(t, \\omega)\\) can also be expressed as \\(X(t)(\\omega)\\) or simply as \\(X(t)\\) or \\(X_t\\). 1.2 Definition of Brownian Motion (#def:Brownian_Motaion) A stochastic process \\(B(t, \\omega)\\) is called a Brownian motion if it satisfies the following conditions: \\(P(\\{\\omega : B(0, \\omega) = 0\\}) = 1\\). For any \\(0 \\leq s &lt; t\\), the random variable \\(B(t) - B(s)\\) is normally distributed with mean 0 and variance \\(t - s\\), i.e., for any \\(a &lt; b\\), \\[ P(a \\leq B(t) - B(s) \\leq b) = \\frac{1}{\\sqrt{2\\pi(t - s)}} \\int_a^b e^{-x^2/2(t - s)} \\, dx. \\] \\(B(t, \\omega)\\) has independent increments, i.e., for any \\(0 \\leq t_1 &lt; t_2 &lt; \\ldots &lt; t_n\\), the random variables \\[B(t_1), B(t_2) - B(t_1), \\ldots, B(t_n) - B(t_{n-1})\\] are independent. Almost all sample paths of \\(B(t, \\omega)\\) are continuous functions, i.e., \\[P(\\{\\omega : B(\\cdot, \\omega) \\text{ is continuous}\\}) = 1\\]. 1.3 Simple Properties of Brownian Motion Let\\(B(t)\\) be a fixed Brownian motion. We give below some simple properties that follow directly from the definition of Brownian motion. Proposition 1.1 For any \\(t &gt; 0\\), \\(B(t)\\) is normally distributed with mean 0 and variance \\(t\\). For any \\(s, t \\geq 0\\), we have \\(\\mathbb{E}[B(s)B(t)] = \\min\\{s, t\\}\\). Remark. Regarding Definition @ref(def:Brownian_Motaion), it can be proved that condition (2) and E[B(s)B(t)] = min{s, t} imply condition (3). Proof. By condition (1), we have \\(B(t) = B(t)−B(0)\\) and so the first assertion follows from condition (2). With out loss of generlity, assume that \\(s&lt;t\\). \\[\\mathbb{E}[B(s)B(t)] = \\mathbb{E}[B(s)(B(t) - B(s)) + B(s)^2]= 0 + s = s\\] which is equal to \\(\\min\\{s, t\\}\\). Proposition 1.2 (Translation Invariance) For a fixed \\(t_0 \\geq 0\\), the stochastic process \\(B(t) = B(t + t_0) - B(t_0)\\) is also a Brownian motion. Proposition 1.3 (Scaling invariance) For any real number \\(\\lambda &gt; 0\\), the stochastic process \\(B(t) = \\frac{B(\\lambda t)}{\\sqrt{\\lambda}}\\) is also a Brownian motion. 1.4 Wiener Integral "],["introduction.html", "Chapter 2 Introduction 2.1 Integrals 2.2 Random Walks", " Chapter 2 Introduction 2.1 Integrals First we review the definitions of the Riemann integral in calculus and the Riemann–Stieltjes integral in advanced calculus. 2.1.1 Riemann Integral Let \\(f\\) be an bounded function defined on a finite closed interval \\([a, b]\\). Then \\(f\\) is called Riemann integrable if the following limit exists. \\[\\begin{equation} x \\end{equation}\\] 2.2 Random Walks Consider a random walk starting at 0 with jumps \\(h\\) and \\(-h\\) equally likely at times \\(\\delta, 2\\delta,...\\), where \\(h,\\delta&gt;0\\) . More precisely, let \\(\\{X_n\\}_{n=1}^\\infty\\) be a sequence of independent and identically distributed random variables with \\[P(X_j = h) = P(X_j = −h) = \\frac{1}{2}\\] Let \\(Y_{\\delta,h}(0) =0\\) \\[Y_{\\delta,h}(n\\delta) = X_1 + X_2 + \\ldots + X_n\\] For \\(t &gt; 0\\) define \\(Y_{\\delta,h}(t)\\) by linearization: (i.e: For \\(n\\delta &lt; t &lt; (n + 1)\\delta\\), define \\[Y_{\\delta,h}(t) = \\frac{(n + 1)\\delta - t}{\\delta} Y_{\\delta,h}(n\\delta) + \\frac{t - n\\delta}{\\delta} Y_{\\delta,h}((n + 1)\\delta).\\] "],["random-walk-to-brownier-motion..html", "Chapter 3 Random Walk to Brownier Motion.", " Chapter 3 Random Walk to Brownier Motion. Slandered approach model stochastic dynamic in discrete time. Let \\(\\eta_i\\) be an random variable on a conman probability space. We often \\(\\Omega,\\mathcal{F},P\\) assume that i.i.d. This case \\(\\eta _i\\) is called white noise, otherwise coloured noise. Now we have definite dynamics. It will be given as discreate time dynamical systems recursively by some non linear function. We define, \\[\\begin{equation} X_{n+1}=X_n+\\phi_{n+1}(X_n,\\eta_{n+1}) \\quad n=0,1,2,...\\tag{3.1} \\end{equation}\\] where \\(\\phi_n:\\mathbb{R}^d\\times \\mathbb{R}^d\\to \\mathbb{R}^d\\) are measurable. Further, if \\(X_0\\) and \\(\\eta_0\\) are all independent then \\(X_n\\) is called Markov Chain. Now let \\(\\eta_i\\) be i.i.d and defineda random walk \\[\\begin{align} S_n&amp;:=\\sum_{i=1}^n \\eta_i\\\\ S_{(n+1)}&amp;:=S_n+\\eta_{(n+1)} \\end{align}\\] We can rewrite (3.1) as \\[X_{n+1}-X_n=\\phi_{n+1}(X_n,S_{n+1}-S_n)\\quad n=0,1,...\\] This equation is called Stochastic difference equations. AIM: Develop a continuous time analogous. Question What to use an contionus time replacement of the random walks? Definition 3.1 Let \\(I\\) be index set \\((I=\\mathbb{N} \\text{ or } I=\\mathbb{R}^+)\\). A collection of random varibels \\((X_t)_{i\\in I}\\) on \\((\\Omega,\\mathcal{F},P)\\) is called staocastic process. We need \\(I\\) to be a just totally ordered set for convention of time. If it is not an totally ordered set it is not a stochastic process but a random field. Now we need a notation of a filtration. Definition 3.2 Le \\(\\mathcal{F}_t\\) be non-decreasing sequnce of sub sigma algbers of \\(\\mathcal{F}\\) (i.e. \\(\\mathcal{F}_s\\subseteq \\mathcal{F}_t\\) for all \\(s\\geq t, s,t\\in \\in I\\)), then \\((\\mathcal{F}_t)_{t\\in I}\\) is called a filtration. Last we need the notation adaptness. Definition 3.3 A stoc "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
